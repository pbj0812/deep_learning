{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = seq_length = 3\n",
    "data_dim = 4 #data variable\n",
    "hidden_dim = 4\n",
    "output_dim = 1\n",
    "learning_rate = 0.05\n",
    "iterations = 100\n",
    "n_inputs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 2. 3. 4. 5.]\n",
      "  [1. 2. 3. 4. 5.]\n",
      "  [1. 2. 3. 4. 5.]\n",
      "  [1. 2. 3. 4. 5.]]]\n",
      "[[[1. 2. 3. 4.]\n",
      "  [5. 1. 2. 3.]\n",
      "  [4. 5. 1. 2.]\n",
      "  [3. 4. 5. 1.]\n",
      "  [2. 3. 4. 5.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1., 2., 3., 4., 5.],\n",
    "              [1., 2., 3., 4., 5.],\n",
    "              [1., 2., 3., 4., 5.],\n",
    "              [1., 2., 3., 4., 5.],\n",
    "             ]])\n",
    "print(x)\n",
    "\n",
    "x = np.reshape(x,[1, 5, 4]) # data reshape\n",
    "print(x)\n",
    "y = np.array([[1., 2., 3., 4., 5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = x[:4]\n",
    "trainY = y[:4]\n",
    "testX = x[4:]\n",
    "testY = y[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 5, data_dim]) # 5 -> data length\n",
    "Y = tf.placeholder(tf.float32, [None, 5]) # 5 -> data length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell():\n",
    "    cell = rnn.BasicLSTMCell(hidden_dim, state_is_tuple = True)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = rnn.BasicLSTMCell(num_units = hidden_dim, state_is_tuple = True)\n",
    "multi_cells = rnn.MultiRNNCell([lstm_cell() for _ in range(5)], state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "train = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 1] loss: 55.00187683105469\n",
      "[step: 2] loss: 43.83588409423828\n",
      "[step: 3] loss: 33.457496643066406\n",
      "[step: 4] loss: 21.829246520996094\n",
      "[step: 5] loss: 13.607568740844727\n",
      "[step: 6] loss: 10.613224029541016\n",
      "[step: 7] loss: 10.056053161621094\n",
      "[step: 8] loss: 10.00294303894043\n",
      "[step: 9] loss: 10.000090599060059\n",
      "[step: 10] loss: 10.000001907348633\n",
      "[step: 11] loss: 10.0\n",
      "[step: 12] loss: 10.0\n",
      "[step: 13] loss: 10.0\n",
      "[step: 14] loss: 10.0\n",
      "[step: 15] loss: 10.0\n",
      "[step: 16] loss: 10.0\n",
      "[step: 17] loss: 10.0\n",
      "[step: 18] loss: 10.0\n",
      "[step: 19] loss: 10.0\n",
      "[step: 20] loss: 10.0\n",
      "[step: 21] loss: 10.0\n",
      "[step: 22] loss: 10.0\n",
      "[step: 23] loss: 10.0\n",
      "[step: 24] loss: 10.0\n",
      "[step: 25] loss: 10.0\n",
      "[step: 26] loss: 10.0\n",
      "[step: 27] loss: 10.0\n",
      "[step: 28] loss: 10.0\n",
      "[step: 29] loss: 10.0\n",
      "[step: 30] loss: 10.0\n",
      "[step: 31] loss: 10.0\n",
      "[step: 32] loss: 10.0\n",
      "[step: 33] loss: 10.0\n",
      "[step: 34] loss: 10.0\n",
      "[step: 35] loss: 10.0\n",
      "[step: 36] loss: 10.0\n",
      "[step: 37] loss: 10.000000953674316\n",
      "[step: 38] loss: 10.000007629394531\n",
      "[step: 39] loss: 10.000068664550781\n",
      "[step: 40] loss: 10.000720024108887\n",
      "[step: 41] loss: 10.008625030517578\n",
      "[step: 42] loss: 10.114276885986328\n",
      "[step: 43] loss: 11.23151683807373\n",
      "[step: 44] loss: 13.01725959777832\n",
      "[step: 45] loss: 11.004385948181152\n",
      "[step: 46] loss: 10.178325653076172\n",
      "[step: 47] loss: 10.021551132202148\n",
      "[step: 48] loss: 10.004401206970215\n",
      "[step: 49] loss: 10.001161575317383\n",
      "[step: 50] loss: 10.000421524047852\n",
      "[step: 51] loss: 10.000198364257812\n",
      "[step: 52] loss: 10.000120162963867\n",
      "[step: 53] loss: 10.000090599060059\n",
      "[step: 54] loss: 10.00008773803711\n",
      "[step: 55] loss: 10.000102043151855\n",
      "[step: 56] loss: 10.000144958496094\n",
      "[step: 57] loss: 10.000249862670898\n",
      "[step: 58] loss: 10.000518798828125\n",
      "[step: 59] loss: 10.001275062561035\n",
      "[step: 60] loss: 10.003721237182617\n",
      "[step: 61] loss: 10.012653350830078\n",
      "[step: 62] loss: 10.049906730651855\n",
      "[step: 63] loss: 10.207212448120117\n",
      "[step: 64] loss: 10.727592468261719\n",
      "[step: 65] loss: 11.053153038024902\n",
      "[step: 66] loss: 10.6447114944458\n",
      "[step: 67] loss: 10.183008193969727\n",
      "[step: 68] loss: 10.059721946716309\n",
      "[step: 69] loss: 10.021085739135742\n",
      "[step: 70] loss: 10.010005950927734\n",
      "[step: 71] loss: 10.005809783935547\n",
      "[step: 72] loss: 10.004327774047852\n",
      "[step: 73] loss: 10.003931045532227\n",
      "[step: 74] loss: 10.004440307617188\n",
      "[step: 75] loss: 10.006011009216309\n",
      "[step: 76] loss: 10.009881973266602\n",
      "[step: 77] loss: 10.018966674804688\n",
      "[step: 78] loss: 10.042774200439453\n",
      "[step: 79] loss: 10.104198455810547\n",
      "[step: 80] loss: 10.256891250610352\n",
      "[step: 81] loss: 10.465343475341797\n",
      "[step: 82] loss: 10.530376434326172\n",
      "[step: 83] loss: 10.308780670166016\n",
      "[step: 84] loss: 10.160865783691406\n",
      "[step: 85] loss: 10.073841094970703\n",
      "[step: 86] loss: 10.040560722351074\n",
      "[step: 87] loss: 10.025056838989258\n",
      "[step: 88] loss: 10.019447326660156\n",
      "[step: 89] loss: 10.017655372619629\n",
      "[step: 90] loss: 10.01966667175293\n",
      "[step: 91] loss: 10.025283813476562\n",
      "[step: 92] loss: 10.038545608520508\n",
      "[step: 93] loss: 10.064308166503906\n",
      "[step: 94] loss: 10.11716365814209\n",
      "[step: 95] loss: 10.196802139282227\n",
      "[step: 96] loss: 10.287270545959473\n",
      "[step: 97] loss: 10.285140991210938\n",
      "[step: 98] loss: 10.22760009765625\n",
      "[step: 99] loss: 10.139005661010742\n",
      "[step: 100] loss: 10.089914321899414\n"
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    _, cost = sess.run([train, loss], feed_dict={X: trainX, Y:trainY})\n",
    "    print(\"[step: {}] loss: {}\".format(i+1, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
